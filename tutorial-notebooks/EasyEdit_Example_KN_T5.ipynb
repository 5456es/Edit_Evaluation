{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyEdit Example with T5 and KN\n",
    "\n",
    "The following example shows how to use KN edit with T5.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Except for installing all the necessary dependencies, you need to download the pre-trained language model. The default hparams in the 'hparams' folder use huggingface cache in default. You can change the 'model_name' in hparam file to the model name to let huggingface automatically download the model for you. In our example, it means changing the 'model_name' to t5-3B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyeditor import KNHyperParams\n",
    "from easyeditor import BaseEditor\n",
    "import os\n",
    "\n",
    "hparams = KNHyperParams.from_hparams(\"Your_Path_To_Repo/EasyEdit/hparams/KN/t5-3B.yaml\")\n",
    "\n",
    "prompts = ['Who was the designer of Lahti Town Hall?']\n",
    "target_new = ['Joe Biden']\n",
    "subject = ['Lahti Town Hall']\n",
    "\n",
    "editor=BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=None,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "    keep_original_weight=False\n",
    ")\n",
    "print(metrics)\n",
    "print(type(edited_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "```\n",
    "Getting coarse neurons for each prompt...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:02<00:00, 62.81s/it]\n",
    "\n",
    "61 coarse neurons found - refining\n",
    "61 neurons remaining after refining\n",
    "\n",
    "Before modification - groundtruth probability: tensor([2.5644e-29], device='cuda:4')\n",
    "Argmax completion: `</s></s><extra_id_5>`\n",
    "Argmax prob: 0.21097961723932296\n",
    "\n",
    "After modification - groundtruth probability: tensor([4.9062e-22], device='cuda:4')\n",
    "Argmax completion: `dendendenden`\n",
    "Argmax prob: 0.9392140688144989\n",
    "2023-11-13 20:50:04,281 - easyeditor.editors.editor - INFO - Execution 0 editing took 63.00693202018738\n",
    "11/13/2023 20:50:04 - INFO - easyeditor.editors.editor -   Execution 0 editing took 63.00693202018738\n",
    "2023-11-13 20:50:04,359 - easyeditor.editors.editor - INFO - Evaluation took 0.07802677154541016\n",
    "11/13/2023 20:50:04 - INFO - easyeditor.editors.editor -   Evaluation took 0.07802677154541016\n",
    "2023-11-13 20:50:04,359 - easyeditor.editors.editor - INFO - 0 editing: Who was the designer of Lahti Town Hall? -> Joe Biden  \n",
    " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who was the designer of Lahti Town Hall?', 'target_new': 'Joe Biden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lahti Town Hall'}, 'time': 63.00693202018738, 'post': {'rewrite_acc': [0.3333333432674408], 'locality': {}, 'portability': {}}}\n",
    "11/13/2023 20:50:04 - INFO - easyeditor.editors.editor -   0 editing: Who was the designer of Lahti Town Hall? -> Joe Biden  \n",
    " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who was the designer of Lahti Town Hall?', 'target_new': 'Joe Biden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lahti Town Hall'}, 'time': 63.00693202018738, 'post': {'rewrite_acc': [0.3333333432674408], 'locality': {}, 'portability': {}}}\n",
    "[{'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who was the designer of Lahti Town Hall?', 'target_new': 'Joe Biden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lahti Town Hall'}, 'time': 63.00693202018738, 'post': {'rewrite_acc': [0.3333333432674408], 'locality': {}, 'portability': {}}}]\n",
    "<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare edited model and original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-3B\")\n",
    "origin_model = T5ForConditionalGeneration.from_pretrained(\"t5-3B\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(prompts, return_tensors='pt', padding=True, max_length=30).to(device)\n",
    "\n",
    "origin_output = origin_model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_length=15\n",
    ")\n",
    "\n",
    "output = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_length=15\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(origin_output, skip_special_tokens=True))\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
